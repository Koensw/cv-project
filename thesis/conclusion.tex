%% ----------------------------------------------------------------------------
% BIWI SA/MA thesis template
%
% Created 09/29/2006 by Andreas Ess
% Extended 13/02/2009 by Jan Lesniak - jlesniak@vision.ee.ethz.ch
%% ----------------------------------------------------------------------------

\chapter{Conclusions and Future Work}
\label{ch:conclusion}
In this work the applicability of self-supervised learning using an ordering task on camera and lidar data was analyzed with the autonomous driving dataset KITTI\cite{geiger2012}. The primary goal was twofold: (1) investigating the performance of a self-supervised task on an autonomous driving dataset and (2) researching the strength of additional input features in the form of lidar data in various representations and examining if those could enhance performance when combined with camera data.

This work has shown that convolutional neural network are definitely able to order frame from driving videos. The binary ordering task has even been considered to be on the easy side for a convolutional neural network to learn. With the more difficult 24-order permutation task, top-1 accuracies close to 60\% were reached, signalling strong and robust performance. The grounds for this strong performance on the self-supervised task were however difficult to discover. It was discovered that the quality of the network filters remain on a relatively low-level scale, and only a limited number of filters are learned. Also more detailed investigations seem to suggest that the network does not learn details about particular objects and instead rely on general correlation between images, although the exact mechanism is unclear. To verify this behavior and to work on alternative approaches to make high-level features easier to learn is an interesting direction for future work. Especially sampling subsets of the frame might be a worthwhile approach to investigate, although that would also imply getting rid of certain features in the field-of-view of the cameras making it impossible to use the frame consistency that is specifically apparent in driving datasets.  

From the perspective of using lidar to enhance the learning, it is evident that it provides strong features for learning. In particular the interpolated lidar depth has been a strong feature in this ordering task, much stronger than the unprocessed lidar. Also the lidar height has shown to be useful for learning, in contrast to the reflectances which did not contain sufficient information for the network to converge. More surprisingly however is that combinations of multiple input features did not show any particular improvement compared to the individual features. However this might come from the lack of input data as earlier fusion was much stronger, suggesting that the network has problems learning all the parameters. In this respect it might be interesting to consider training on larger datasets in the future.

An important step for future work would be to setup a baseline to test the investigated backbones on various alternative tasks like classification and object detection, to gain from the representation learned by the self-supervised task on various input sources. Before this step is deemed viable, more research would be needed to improve the quality of the pre-training. If improvements are possible, the self-supervised task could also be used directly as input to driving models for autonomous cars, which could be a promising possibility for future research as well. 

%Due to time constraints this step could unfortunately not yet been implemented as part of this thesis.

%does unfortuantely however not appear to be directly scalable to different problems in its current state.
