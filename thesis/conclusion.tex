%% ----------------------------------------------------------------------------
% BIWI SA/MA thesis template
%
% Created 09/29/2006 by Andreas Ess
% Extended 13/02/2009 by Jan Lesniak - jlesniak@vision.ee.ethz.ch
%% ----------------------------------------------------------------------------

\chapter{Conclusions and Future Work}
\label{ch:conclusion}
In this work the applicability of self-supervised learning using an ordering task on camera and lidar data was analyzed with the autonomous driving dataset KITTI. The primary goal was twofold: (1) investigating the performance of a self-supervised task on an autonomous driving dataset and (2) researching the strength of additional input features in the form of lidar data in various representations and examining if those could enhance performance when combined with camera data.

This work has shown that convolutional neural network are definitely able to order frames from driving videos. The binary ordering task has even been considered to be on the easy side for a convolutional neural network to learn. With the more difficult 24-order permutation task, top-1 accuracies close to 60\% were reached, signalling strong and robust performance. The grounds for this strong performance on the self-supervised task were however difficult to discover. The quality of the network filters seem to remain on a relatively low-level, and only a limited number of filters are learned. Also more detailed investigations seem to suggest that the network does not learn details about particular objects and instead rely on general correlation between static elements, although the exact mechanism is unclear. To verify this behavior and to work on alternative approaches to make the network learn features of higher level is an interesting direction for future work. Especially sampling subsets of the frame might be a worthwhile approach to investigate, although that would also imply getting rid of certain features in the field-of-view of the cameras making it impossible to use the frame consistency that is specifically apparent in driving datasets.  

From the perspective of using lidar to enhance the training, it is evident that it provides strong features for learning. In particular the interpolated lidar depth has been a strong feature in this ordering task, much stronger than the unprocessed lidar. Also the height above ground has shown to be useful for learning, in contrast to the reflectances which did not contain sufficient information for the network to converge. More surprisingly however is that combinations of multiple input features did not show any particular improvement compared to the individual features in the current state. However this might come from the lack of input data as earlier fusion was much stronger, suggesting that the network has problems learning all the parameters. In this respect it might be interesting to consider training on larger and more complete datasets in the future. Another interesting possibility to research for lidar data is a more detailed study on the performance in different environments, besides the turns that were investigated in this work.

%A final important step for future work would be to setup a measure to test the investigated backbones on various alternative tasks like classification and object detection, but before this fine-tuning step is deemed viable, more research would likely be needed to improve the quality of the pre-training. Creating such a benchmark, which is currently still missing for self-supervised learning with input feature maps from other sources than standard camera images, would however allow to gain a better understanding of the actual performance of the self-supervised task and would help to evaluate improvements to the generalizability of the model. Self-supervised learning remains therefore a promising technique to enhance models for autonomous driving in the future.

A final important step for future work would be to setup a measure to test the investigated backbones on various alternative tasks like classification and object detection. Creating such a benchmark, which is currently still missing for self-supervised learning with input feature maps from other sources than standard camera images, would allow to gain a better understanding of the actual performance of the self-supervised task and would help to evaluate improvements to the generalizability of the model. While in the current state this fine-tuning step may not deemed viable with the limited quality of the filters, self-supervised learning remains a promising technique to enhance models for autonomous driving in the future.

% Such a benchmark is currently still missing for self-supervised learning with input feature maps from other sources than standard camera images. 

%If improvements are possible, the self-supervised task could also be used directly as input to driving models for autonomous cars, which could be a promising possibility for future research as well. 

%Before this step is deemed viable, more research would be needed to improve the quality of the pre-training. 
%Due to time constraints this step could unfortunately not yet been implemented as part of this thesis.

%does unfortuantely however not appear to be directly scalable to different problems in its current state.
