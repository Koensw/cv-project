%% ----------------------------------------------------------------------------
% BIWI SA/MA thesis template
%
% Created 09/29/2006 by Andreas Ess
% Extended 13/02/2009 by Jan Lesniak - jlesniak@vision.ee.ethz.ch
%% ----------------------------------------------------------------------------
\newpage
\chapter{Discussion}
\label{ch:discussion}
In the previous section it has become clear that CNNs are very well capable of learning the ordering task, both the simple 3-input binary task reaching up to 82,84\% accuracy as well as the 4-input 24-output permutation version with an top-1 accuracy of 44,42\% when combining the strongest features efficiently. Especially the accuracy on the OPN4 network is remarkably high, given the fact that even a single error in the estimated order would cause the accuracy to drop. From the acquired results it can therefore definitely be concluded that neural networks are very well capable of sorting image frames acquired from driving cameras, an interesting result for itself. The studied network based on the earlier proposed OPN network \cite{lee2017} apparently scales well to the Kitti dataset and also to various other feature maps including lidar.

[It has been shown that particularly the color images, the interpolated lidar depth and the estimated lidar height above ground provide strong features for the network to train on. This mostly follows expectations, although it is interesting to note that color images and the interpolated lidar are features with similar strengths, while the height above ground is superior to both of those.]

While the neural networks have definitely shown to be capable learning this task, it interesting to find out what representation the networks actually primarily learn. As the task does not (directly) require the detection of any object it is not directly expected that the network only learns to detect a particular class of objects. Can we gain an overview what the backbone network exactly learns? 

With the several millions of parameters contained in a neural network, this is not a particularly easy task. However several methods have been developed to visualize neural networks. The simplest and remarkably effective way to investigate the strength of the learning is to look at the first-order convolutional layers. The filters in those layers are applied directly on the image and they therefore contain first-level patterns the network learns. The first-order filters that are learned from the [various] individual feature maps are shown in Figure \needfig where for reference also the features learned by the Alexnet architecture\cite{krizhevsky2012} on Imagenet are included. Note first that all of the maps, except the images from the color camera, do only have one layer and are therefore shown in grayscale. 

It is immediately clear that the filters on Alexnet are significantly stronger, but this could be expected as they are trained on large supervised data set, in contrast to the other maps trained on the self-supervised ordering task. In general it is however clear that only a limited number of simple edge and corner filters are learned and those filters are not fully smooth. [COMPARE FILTERS] Approximately half of the filters can however be considered 'dead' as they contain only a noise pattern, from which it appears only a limited number of filters is apparently adequate for solving the task.

To investigate this in more detail where the network focuses on, two alternative visualizing techniques are investigated: saliency maps and maximally activated regions. Figure \needfig shows various saliency maps on the different features split over different frames. The saliency map should give an indication of the most important part of the image in the classification, but it does unfortunately not show a particular attention to a certain detail of a particular kind of object, for example cars. There is also not an very apparent overlap between the same objects that is tracked through multiple frames in the sequence. Instead the most important part of the image appear to be focused on the inner side of every single frame, suggesting that a zoomed in version might be used to compare it to the next frame. Interestingly enough it appears that the network is partly even ignoring the moving car, just focusing on the parts which appear statically in both images.  

Directly correlating corresponding parts in the image would be an anticipated approach, but it has not been expected to be so efficient directly, given the complex movement around the streets, with cars passing in the other direction, traffic crossing the street and the car turning, but this picture seems to give an indication that the indirect correlation approach comparing the relatively simple patterns learned from the backbone network between the different images might still be a strong feature. It is however hard to conclude this confidently, as the saliency maps might not give the complete picture. This technique has not been applied in this context before and there exists therefore no relevant literature to compare with.

A similar approach to find the important regions on the image is to find the location of the maximal activated neurons in the higher layers, for example in the fifth convolutional layer. For comparison with the previous approach the 5 maximal regions are shown for one of the frames investigated with the saliency map is shown in Figure \needfig. It is again hard to point which features the network is exactly focusing on, but there seems again a general tendency on several general static objects, for example trees around and the contour in the road. It remains however difficult to generalize a particular feature over multiple frames.

% \begin{itemize}
%  \item \textit{What do your results mean?} Here you discuss, but you do not recapitulate results. Describe principles, relationships and generalizations shown. Also, mention inconsistencies or exceptions you found.
%  \item \textit{How do your results relate to other's work?} Show how your work agrees or disagrees with other's work. Here you can rely on the information you presented in the ``related work'' section.
%  \item \textit{What are implications and applications of your work?} State how your methods may be applied and what implications might be. 
% \end{itemize}
% 
% \noindent Make sure that introduction/related work and the discussion section act as a pair, i.e. ``be sure the discussion section answers what the introduction section asked''. 
